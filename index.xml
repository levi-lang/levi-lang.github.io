<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Minimal</title>
    <link>https://levi-lang.github.io/</link>
    <description>Recent content on Minimal</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 18 Jul 2022 04:39:11 +0100</lastBuildDate><atom:link href="https://levi-lang.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>kubesphere 监控: prometheus</title>
      <link>https://levi-lang.github.io/post/prometheus/</link>
      <pubDate>Mon, 18 Jul 2022 04:39:11 +0100</pubDate>
      
      <guid>https://levi-lang.github.io/post/prometheus/</guid>
      <description>参考地址： https://www.kancloud.cn/panxin20/notes/1923544 https://prometheus-operator.dev/docs/prologue/introduction/ 监控原则 1、监控是基础设施，目的是为了解决问题 不要只朝着大而全去做，尤其是不必要的指标采集 浪费人力和存储资源（To B商业产品例外） 2、需要处理的告警才发出来，发出来的告警必须得到处理 3、简单的架构就是最好的架构，业务系统都挂了，监控也不能挂 Google Sre 里面也说避免使用 Magic 系统，例如机器学习报警阈值、自动修复之类 这一点见仁见智吧，感觉很多公司都在搞智能 AI 运维 原理 Prometheus从exporter拉取数据，或者间接地通过网关gateway拉取数据 如果在k8s内部署，可以使用服务发现的方式 它默认本地存储抓取的所有数据，并通过一定规则进行清理和整理数据 并把得到的结果存储到新的时间序列中，采集到的数据有两个去向 一个是报警，另一个是可视化 PromQL和其他API可视化地展示收集的数据，并通过Alertmanager提供报警能力 输出被监控组件信息的HTTP接口被叫做exporter 目前互联网公司常用的组件大部分都有exporter可以直接使用 比如Varnish、Haproxy、Nginx、MySQL、Linux系统信息包括磁盘、内存、CPU、网络等等 endpoint endpoint是k8s集群中的一个资源对象，存储在etcd中，用来记录一个service对应的所有pod的访问地址。 service配置selector，endpoint controller才会自动创建对应的endpoint对象； 否则，不会生成endpoint对象. 部署方式 二进制 容器 Kubernetes Deployment Helm Kubernetes package manager Operator prometheus-operator(官方：无内置规则) kube-prometheus(官方：有内置规则) prometheus的局限 1、Prometheus 是基于 Metric 的监控，不适用于日志（Logs）、事件(Event)、调用链(Tracing)。 2、Prometheus 默认是 Pull 模型，合理规划你的网络，尽量不要转发。 3、对于集群化和水平扩展，官方和社区都没有银弹，需要合理选择 Federate、Cortex、Thanos等方案。 4、监控系统一般情况下可用性大于一致性，容忍部分副本数据丢失，保证查询请求成功 5、Prometheus 不一定保证数据准确 这里的不准确一是指 rate、histogram_quantile 等函数会做统计和推断 产生一些反直觉的结果，这个后面会详细展开 二来查询范围过长要做降采样，势必会造成数据精度丢失 不过这是时序数据的特点，也是不同于日志系统的地方。 合理选择黄金指标 采集的指标有很多，我们应该关注哪些？ Google 在“Sre Handbook”中提出了“四个黄金信号”：延迟、流量、错误数、饱和度。 实际操作中可以使用 Use 或 Red 方法作为指导，Use 用于资源，Red 用于服务 Use 方法：Utilization、Saturation、Errors。如 Cadvisor 数据 Red 方法：Rate、Errors、Duration。如 Apiserver 性能指标 Prometheus 采集中常见的服务分三种： 在线服务： 如 Web 服务、数据库等，一般关心请求速率，延迟和错误率即 RED 方法 离线服务： 如日志处理、消息队列等，一般关注队列数量、进行中的数量，处理速度以及发生的错误即 Use 方法 批处理任务： 和离线任务很像，但是离线任务是长期运行的 批处理任务是按计划运行的，如持续集成就是批处理任务 对应 K8S 中的 job 或 cronjob 一般关注所花的时间、错误数等，因为运行周期短，很可能还没采集到就运行结束了 所以一般使用 Pushgateway，改拉为推 HPA Horizontal Pod Autoscaling，简称HPA，是Kubernetes中实现POD水平自动伸缩的功能。 它可以根据CPU使用率或应用自定义metrics自动扩展Pod数量 支持 replication controller、deployment 和 replica set v1.</description>
    </item>
    
    <item>
      <title>kubernetes 部署ingress: nginx</title>
      <link>https://levi-lang.github.io/post/ingress/</link>
      <pubDate>Sun, 17 Jul 2022 10:31:11 +0100</pubDate>
      
      <guid>https://levi-lang.github.io/post/ingress/</guid>
      <description>kubernetes ingress Kubernetes Ingress 只是 Kubernetes 中的一个普通资源对象 需要一个对应的 Ingress Controller 来解析 Ingress 的规则，暴露服务到外部 比如 ingress-nginx，本质上来说它只是一个 Nginx Pod 然后将请求重定向到其他内部（ClusterIP）服务去 这个 Pod 本身也是通过 Kubernetes 服务暴露出去，最常见的方式是通过 LoadBalancer 来实现的 ingress 种类 kubernetes Ingress Controller: # Kubernetes 的“官方”控制器 nginx-ingress: # 这是 NGINX 公司开发的官方产品，它也有一个基于 NGINX Plus 的商业版 traefik: # 最初，这个代理是为微服务请求及其动态环境的路由而创建的，因此具有许多有用的功能 apisix: # apisix-ingress-controller 是另一个使用Apache APISIX作为高性能反向代理 Kong Ingress: # Kong Ingress 由 Kong Inc 开发，有两个版本：商业版和免费版 HAProxy Ingress: # HAProxy 是众所周知的代理服务器和负载均衡器 Voyager: # Voyager 基于 HAProxy，并作为一个通用的解决方案提供给大量供应商 Contour: # Contour 和 Envoy 由同一个作者开发，它基于Envoy Istio Ingress # Istio 是 IBM、Google 和 Lyft 的联合开发项目，它是一个全面的服务网格解决方案 Ambassador: # Ambassador 也是一个基于 Envoy 的解决方案，它有免费版和商业版两个版本 Gloo: # Gloo 是在 Envoy 之上构建的新软件 于2018年3月发布 kubernetes 中的服务暴露方式 待补充 安装nginx-ingress 1 首先登录kubesphere 2 创建企业空间 平台管理---访问控制---创建 3 进入企业空间---应用管理---应用仓库---添加 4 名称: nginx URL: https://kubernetes.</description>
    </item>
    
    <item>
      <title>blog 搭建: hugo</title>
      <link>https://levi-lang.github.io/post/blog/</link>
      <pubDate>Sun, 17 Jul 2022 08:14:11 +1000</pubDate>
      
      <guid>https://levi-lang.github.io/post/blog/</guid>
      <description>参考地址 hugo主题: https://themes.gohugo.io/ minimal: https://themes.gohugo.io/themes/minimal/ 安装hugo Mac 安装Hugo brew install hugo 创建blog hugo new site blog cd blog 下载主题 git submodule add https://github.com/calintat/minimal.git themes/minimal git submodule init git submodule update git submodule update --remote themes/minimal cp themes/minimal/exampleSite/config.toml . 编辑文章 mkdir -p blog/content/post cd blog/content/post vim blog.md 启动测试 cd blog hugo server 生成blog cd blog hugo --theme=Minimal --baseUrl=&amp;#34;https://levi-lang.github.io&amp;#34; --buildDrafts 执行完上面的命令 会在blog 目录下的public文件夹中生成网页 上传github cd blog/public git init git add . git commit -m &amp;#34;test&amp;#34; git remote add origin https://github.</description>
    </item>
    
    <item>
      <title>cloud 一选型</title>
      <link>https://levi-lang.github.io/post/cloud/</link>
      <pubDate>Sat, 16 Jul 2022 03:46:11 +0100</pubDate>
      
      <guid>https://levi-lang.github.io/post/cloud/</guid>
      <description>云厂商 国外 亚马逊云 微软云 谷歌云 IBM云 国内 阿里云 腾讯云 华为云 百度云 Ucloud 天翼云 青云 盛大云 语言 C C++ C# Python PHP Java GoLang JavaScript Node.js 运维阶段
人工阶段 脚本阶段 平台化阶段 智能化阶段 IT体系3阶段
物理机体系阶段 云计算体系阶段 容器体系阶段 技术架构4阶段
单机架构的阶段 集群架构的阶段 分布式架构阶段 微服务架构阶段 云端网络的三种选择策略 策略一选型的五个注意点 网段方面 经典网络的内网IP 是以10开头的随机IP 且内网IP只能随机分配 不能自定义 而在VPC网络中 每个客户都是独立的网络环境 客户可以自定义网络的IP段 网卡方面 经典网络绑定公网的ECS（linux系统） 系统中网卡是两个网卡 eth0是内网网卡 eth1是公网网卡 如果没有绑定公网 则经典网络仅有一个内网eth0 而VPC网络 及时绑定了弹性IP的ECS网卡也只有一个eth0 即不管有没有绑定弹性IP VPC网络的ECS仅有一个eth0网卡 绑定弹性IP的时候 公网数据是通过阿里云内部NAT的方式流转到ECS的eth0网卡上的 经典网络下 开通后没办法再绑定公网 弹性IP针对VPC网络 网络隔离方面 经典网络客户和客户之间的数据通过安全组三层隔离 如果需要互通 安全组配置互访规则即可 经典网络安全组实践案例 通过简单地配置安全局互访规则 VPC和VPC之间默认二层隔离 如果需要互通只能高速通道（专线） 网络功能方面 上述网段划分、网段隔离功能 仅VPC网络支持 自建VPN（阿里云VPN网关服务）、阿里云高速通道（专线）的功能支持 都依托VPC网络 这意味着混合云的架构必须基于VPC网络环境 如果用经典网络环境是没办法将两个环境的内网进行互通的 另外经典网络仅支持DNAT 而VPC网络却能支持DNAT和SNAT 网络实践方面 经典网络：一般适合部署个人应用 个人站点 VPC网络：企业默认的网络架构 策略二入网请求选型的四种方法 在云端对ECS实现入网请求的功能 可以通过一下四种方式实现 SLB网络：七层和四层的负载均衡 都能将公网的流量引入到ECS中 公网IP：经典网络的公网IP 能直接将公网的请求流量引入到ECS中的eth1网卡上 弹性EIP：VPC专有网络的弹性EIP 能直接将公网的请求流量引入到ECS中的eth0网卡上 DNAT：通过端口映射能直接将公网的流量映射到ECS的内网端口上 通过以上四种方法 把云端入网请求的类型划分为一下两大类 负载均衡类 负载均衡类 一般都是多台机器同时对外提供服务 尤其是在web应用中尤为常见 公网IP类 公网IP类 是云端时间中为ECS提供公网访问的最常见做法 为ECS直接绑定公网主要的场景需求有三点 1、ECS服务需要暴露给公网 2、需要公网远程登录到这台服务器进行维护 3、ECS上部署的服务需要去公网调用及请求第三方的服务及接口 通过以上3点 让每台服务器都绑定公网几乎完全没有意义 1、服务暴露给公网 可以通过slb 或者 nginx 进行转发 2、远程登录 可以设置堡垒机 3、对于服务器需要去公网请求第三方服务及接口 采用NAT网关的SNAT功能即可 直接绑定公网一般适用于在服务器上部署了FTP等功能 由于服务协议的关系 没办法直接通过SLB负载均衡的方式吧服务暴露给公网 </description>
    </item>
    
    <item>
      <title>kubernetes 部署工具: kubekey</title>
      <link>https://levi-lang.github.io/post/kubekey/</link>
      <pubDate>Sat, 16 Jul 2022 03:46:11 +0100</pubDate>
      
      <guid>https://levi-lang.github.io/post/kubekey/</guid>
      <description>kubernetes 安装的方式 二进制 minikube kind kubeadm kubespray sealos kubeasz kubekey KOPS k3s rancher 每台机器必须要安装 yum install socat ipvsadm conntrack -y systemctl stop postfix &amp;amp;&amp;amp; systemctl disable postfix systemctl stop firewalld &amp;amp;&amp;amp; systemctl disable firewalld setenforce 0 &amp;amp;&amp;amp; sed -i &amp;#39;s/^SELINUX=.*/SELINUX=disabled/&amp;#39; /etc/selinux/config curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun vim /etc/docker/daemon.json { &amp;#34;log-driver&amp;#34;:&amp;#34;json-file&amp;#34;, &amp;#34;log-opts&amp;#34;: {&amp;#34;max-size&amp;#34;:&amp;#34;9G&amp;#34;, &amp;#34;max-file&amp;#34;:&amp;#34;3&amp;#34;}, &amp;#34;registry-mirrors&amp;#34;: [&amp;#34;https://7a1tnjfc.mirror.aliyuncs.com&amp;#34;], &amp;#34;data-root&amp;#34;:&amp;#34;/data/docker&amp;#34;, &amp;#34;dns&amp;#34; : [&amp;#34;114.114.114.114&amp;#34;,&amp;#34;8.8.8.8&amp;#34;] } systemctl daemon-reload &amp;amp;&amp;amp; systemctl restart docker &amp;amp;&amp;amp; systemctl enable docker 使用kubekey 安装 参考地址: github: https://github.</description>
    </item>
    
  </channel>
</rss>
